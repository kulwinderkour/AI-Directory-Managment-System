# Environment Configuration
ENVIRONMENT=development

# AI Provider Configuration
# Options: "ollama" (local) or "gemini" (cloud-based)
AI_PROVIDER=ollama

# Ollama Configuration (for local AI - free & private)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Gemini Configuration (for cloud-based AI)
# Get your API key from: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-pro
GEMINI_EMBEDDING_MODEL=models/embedding-001

# Database Configuration
DATABASE_URL=sqlite:///./lumina.db
CHROMA_PERSIST_DIR=./chroma_db

# Server Configuration
CORS_ORIGINS=["http://localhost:3000","http://127.0.0.1:3000"]
MAX_FILE_SIZE=52428800
MAX_FILES_PER_BATCH=10000

# AI Configuration
MAX_TOKENS=4000
TEMPERATURE=0.7
EMBEDDING_BATCH_SIZE=100
